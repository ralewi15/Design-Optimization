{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attempted-merchandise",
   "metadata": {},
   "source": [
    "# Project 1: Gradient-based Algorithms and Differentiable Programming\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "Consider a simple formulation of rocket landing where the rocket state $x(t)$ is represented by its distance to the ground $d(t)$ and its velocity $v(t)$, i.e., $x(t) = [d(t), v(t)]^T$, where $t$ specifies time. The control input of the rocket is its acceleration $a(t)$. The discrete-time dynamics follows \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "d(t+1) = d(t) + v(t) \\Delta t, \\\\\n",
    "v(t+1) = v(t) + a(t) \\Delta t,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\Delta t$ is a time interval. Further, let the closed-loop controller be \n",
    "\n",
    "$$\n",
    "a(t) = f_{\\theta}(x(t))\n",
    "$$\n",
    "\n",
    "where $f_{\\theta}(\\cdot)$ is a neural network with parameters $\\theta$, which are to be determined through optimization.\n",
    "\n",
    "For each time step, we assign a loss as a function of the control input and the state: $l(x(t),a(t))$. In this example, we will simply set $l(x(t),a(t))=0$ for all $t=1,...,T-1$, where $T$ is the final time step, and $l(x(T),a(T)) = ||x(T)||^2 = d(T)^2 + v(T)^2$. This loss encourages the rocket to reach $d(T)=0$ and $v(T)=0$, which are proper landing conditions.\n",
    "\n",
    "The optimization problem is now formulated as\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\theta} \\quad & ||x(T)||^2 \\\\\n",
    "\\quad & d(t+1) = d(t) + v(t) \\Delta t, \\\\\n",
    "\\quad & v(t+1) = v(t) + a(t) \\Delta t, \\\\\n",
    "\\quad & a(t) = f_{\\theta}(x(t)), ~\\forall t=1,...,T-1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "While this problem is constrained, it is easy to see that the objective function can be expressed as a function of $x(T-1) and a(T-1)$, where $x(T-1)$ as a function of $x(T-2)$ and $a(T-2)$, and so on. Thus it is essentially an unconstrained problem with respect to $\\theta$. \n",
    "\n",
    "In the following, we code this problem up with [PyTorch](https://pytorch.org/), which allows us to only build the forward pass of the loss (i.e., how we move from $x(1)$ to $x(2)$ and all the way to $x(T)$) and automatically get the gradient $\\nabla_{\\theta} l(x(T),a(T))$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee637dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "center-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overhead\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "induced-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment parameters\n",
    "\n",
    "FRAME_TIME = 0.1  # time interval\n",
    "GRAVITY_ACCEL = 0.12  # gravity constant\n",
    "BOOST_ACCEL = 0.18  # thrust constant\n",
    "rho = 10000 #arbitrary number for atmospheric pressure because atmoshpere conditions are unknown\n",
    "Cd = 75 #Arbitrary number for drag coefficenent for rocket\n",
    "A= 0.0625 # Arbitrary effective area of Rocket\n",
    "# # the following parameters are not being used in the sample code\n",
    "# PLATFORM_WIDTH = 0.25  # landing platform width\n",
    "# PLATFORM_HEIGHT = 0.06  # landing platform height\n",
    "ROTATION_ACCEL = 20  # rotation constant\n",
    "#ASSUMING ROTATION ACCEL DEGREES/S^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "injured-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define system dynamics\n",
    "# Notes: \n",
    "# 0. You only need to modify the \"forward\" function\n",
    "# 1. All variables in \"forward\" need to be PyTorch tensors.\n",
    "# 2. All math operations in \"forward\" has to be differentiable, e.g., default PyTorch functions.\n",
    "# 3. Do not use inplace operations, e.g., x += 1. Please see the following section for an example that does not work.\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Dynamics, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(state, action):\n",
    "\n",
    "        \"\"\"\n",
    "        action: thrust or no thrust\n",
    "        state[0] = y\n",
    "        state[1]=angle\n",
    "        state[2] = y_dot\n",
    "        state[3]=angle_dot\n",
    "        state[4]= drag\n",
    "        state[5]=drag_dot\n",
    "        \"\"\"\n",
    "        # First define drag to create delta_drag\n",
    "        # rho  Atmospheric pressure [Pa]\n",
    "        # v    Velocity [m/s]\n",
    "        v = GRAVITY_ACCEL*FRAME_TIME\n",
    "        # Cd   Drag coefficient\n",
    "        # A    Effective area [m^2]\n",
    "        def drag(self, rho, v, Cd, A):\n",
    "            return 0.5 * rho * Cd * A * v**2\n",
    "        # Apply gravity\n",
    "        # Note: Here gravity is used to change velocity which is the second element of the state vector\n",
    "        # Normally, we would do x[1] = x[1] + gravity * delta_time\n",
    "        # but this is not allowed in PyTorch since it overwrites one variable (x[1]) that is part of the computational graph to be differentiated.\n",
    "        # Therefore, I define a tensor dx = [0., gravity * delta_time], and do x = x + dx. This is allowed... \n",
    "        delta_state_gravity = t.tensor([0., 0., GRAVITY_ACCEL * FRAME_TIME, ROTATION_ACCEL*FRAME_TIME, 0., 0.])\n",
    "\n",
    "        # Thrust\n",
    "        # create theta_dot as 4x1 tensor* action where fourth variable is rotational accel\n",
    "\n",
    "\n",
    "        delta_angle = t.tensor([0., 0.,0.,ROTATION_ACCEL*FRAME_TIME, 0., 0.]) * action\n",
    "        \n",
    "        # Note: Same reason as above. Need a 6-by-1 tensor.\n",
    "        delta_state = math.cos((math.pi*ROTATION_ACCEL*FRAME_TIME/180))*BOOST_ACCEL * FRAME_TIME * t.tensor([0., 0.,-1.,0., 0., 0.])*action\n",
    "        # Create delta_drag\n",
    "        delta_drag = t.tensor([0., 0.,0.,0., 0., GRAVITY_ACCEL*FRAME_TIME]) * action\n",
    "        #Not sure what to make the delta_drag function\n",
    "        # made the delta drag function have GRAVITY_ACCEL*FRAME_TIME  because it is the only non constant value in drag\n",
    "        \n",
    "        # Note: Same as above. Use operators on matrices/tensors as much as possible. Do not use element-wise operators as they are considered inplace.\n",
    "        step_mat = t.tensor([[1., FRAME_TIME, 0., 0., 0., 0.],\n",
    "                            [0.,ROTATION_ACCEL*FRAME_TIME,0., 0., 0., 0.],\n",
    "                             [0., 0., GRAVITY_ACCEL,0., 0., 0.],\n",
    "                             [0., 0., 0., ROTATION_ACCEL, 0., 0.],\n",
    "                             [0., 0., 0.,0., drag, 0.], \n",
    "                             [0., 0., 0.,0., 0., GRAVITY_ACCEL]])\n",
    "\n",
    "        # Update velocity\n",
    "        state = state + delta_state + delta_state_gravity + delta_angle+delta_drag\n",
    "        # Update state\n",
    "        state = t.matmul(step_mat, state)\n",
    "       \n",
    "\n",
    "        return state\n",
    "        print(type(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "controlling-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a deterministic controller\n",
    "# Note:\n",
    "# 0. You only need to change the network architecture in \"__init__\"\n",
    "# 1. nn.Sigmoid outputs values from 0 to 1, nn.Tanh from -1 to 1\n",
    "# 2. You have all the freedom to make the network wider (by increasing \"dim_hidden\") or deeper (by adding more lines to nn.Sequential)\n",
    "# 3. Always start with something simple\n",
    "\n",
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_input, dim_hidden, dim_output):\n",
    "        \"\"\"\n",
    "        dim_input: # of system states\n",
    "        dim_output: # of actions\n",
    "        dim_hidden: up to you\n",
    "        \"\"\"\n",
    "        super(Controller, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(dim_input, dim_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim_hidden, dim_output),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        action = self.network(state)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bibliographic-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simulator that rolls out x(1), x(2), ..., x(T)\n",
    "# Note:\n",
    "# 0. Need to change \"initialize_state\" to optimize the controller over a distribution of initial states\n",
    "# 1. self.action_trajectory and self.state_trajectory stores the action and state trajectories along time\n",
    "\n",
    "class Simulation(nn.Module):\n",
    "\n",
    "    def __init__(self, controller, dynamics, T):\n",
    "        super(Simulation, self).__init__()\n",
    "        self.state = self.initialize_state()\n",
    "        self.controller = controller\n",
    "        self.dynamics = dynamics\n",
    "        self.T = T\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        self.action_trajectory = []\n",
    "        self.state_trajectory = []\n",
    "        for _ in range(T):\n",
    "            action = self.controller.forward(state)\n",
    "            state = self.dynamics.forward(state, action)\n",
    "            self.action_trajectory.append(action)\n",
    "            self.state_trajectory.append(state)\n",
    "        return self.error(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state():\n",
    "        state = [1., 0., 0., 0., 0., 0.]  # TODO: need batch of initial states\n",
    "        return t.tensor(state, requires_grad=False).float()\n",
    "\n",
    "    def error(self, state):\n",
    "        return state[0]**2 + state[1]**2+state[3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "celtic-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "# Note:\n",
    "# 0. LBFGS is a good choice if you don't have a large batch size (i.e., a lot of initial states to consider simultaneously)\n",
    "# 1. You can also try SGD and other momentum-based methods implemented in PyTorch\n",
    "# 2. You will need to customize \"visualize\"\n",
    "# 3. loss.backward is where the gradient is calculated (d_loss/d_variables)\n",
    "# 4. self.optimizer.step(closure) is where gradient descent is done\n",
    "\n",
    "class Optimize:\n",
    "    def __init__(self, simulation):\n",
    "        self.simulation = simulation\n",
    "        self.parameters = simulation.controller.parameters()\n",
    "        self.optimizer = optim.LBFGS(self.parameters, lr=0.01)\n",
    "\n",
    "    def step(self):\n",
    "        def closure():\n",
    "            loss = self.simulation(self.simulation.state)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        self.optimizer.step(closure)\n",
    "        return closure()\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.step()\n",
    "            print('[%d] loss: %.3f' % (epoch + 1, loss))\n",
    "            self.visualize()\n",
    "\n",
    "    def visualize(self):\n",
    "        data = np.array([self.simulation.state_trajectory[i].detach().numpy() for i in range(self.simulation.T)])\n",
    "        x = data[:, 0]\n",
    "        y = data[:, 1]\n",
    "        plt.plot(x, y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "adequate-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of function",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-81-a9e538850b6c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSimulation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# define simulation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# define optimizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m40\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# solve the optimization problem\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-80-f670d8403d27>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, epochs)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'[%d] loss: %.3f'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvisualize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-80-f670d8403d27>\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lbfgs.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m         \u001B[0;31m# evaluate initial f(x) and df/dx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 311\u001B[0;31m         \u001B[0morig_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0mcurrent_evals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-80-f670d8403d27>\u001B[0m in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msimulation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msimulation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m             \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-79-064a84c3c3a1>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m             \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontroller\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m             \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdynamics\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction_trajectory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_trajectory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-77-2649cb63493b>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(state, action)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;31m# Note: Same as above. Use operators on matrices/tensors as much as possible. Do not use element-wise operators as they are considered inplace.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         step_mat = t.tensor([[1., FRAME_TIME, 0., 0., 0., 0.],\n\u001B[0m\u001B[1;32m     55\u001B[0m                             \u001B[0;34m[\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mROTATION_ACCEL\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mFRAME_TIME\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m                              \u001B[0;34m[\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mGRAVITY_ACCEL\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Could not infer dtype of function"
     ]
    }
   ],
   "source": [
    "# Now it's time to run the code!\n",
    "\n",
    "T = 100  # number of time steps\n",
    "dim_input = 6  # state space dimensions\n",
    "dim_hidden = 6  # latent dimensions\n",
    "dim_output = 1  # action space dimensions\n",
    "d = Dynamics()  # define dynamics\n",
    "c = Controller(dim_input, dim_hidden, dim_output)  # define controller\n",
    "s = Simulation(c, d, T)  # define simulation\n",
    "o = Optimize(s)  # define optimizer\n",
    "o.train(40)  # solve the optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-donor",
   "metadata": {},
   "source": [
    "## 3. A Better Problem Formulation\n",
    "\n",
    "Here is a list of things we discussed during the class that could help to make the problem more representative of the reality:\n",
    "\n",
    "1. More realistic definition of state and action spaces: Rocket orientation, angular velocity, etc. \n",
    "2. Better dynamical model, e.g., drag\n",
    "3. Constraints in state and action spaces\n",
    "4. Controller design for a distribution of initial states rather than one\n",
    "5. Randomness in dynamics, sensing, etc.\n",
    "6. Discontinuity in modeling so that gradient cannot be computed, e.g., mechanical failures.\n",
    "\n",
    "In this project, please choose at least one aspect from 1 to 5 from the list to improve your problem formulation and solve the resultant problem. We will address 6 when we talk about reinforcement learning.\n",
    "\n",
    "Here is one example of problem formulation when we consider randomness in dynamics and initial states:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\theta} \\quad & \\mathbb{E}_{\\{w(t), u(t), x(0)\\}}\\left[||x(T)||^2\\right] \\\\\n",
    "\\quad & d(t+1) = d(t) + v(t) + w(t) \\Delta t, \\\\\n",
    "\\quad & v(t+1) = v(t) + a(t) + u(t) \\Delta t, \\\\\n",
    "\\quad & a(t) = f_{\\theta}(x(t)), ~\\forall t=1,...,T-1 \\\\\n",
    "\\quad & x(1) \\sim \\Pr(x(1))\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here $w(t) \\sim \\Pr(w(t))$ and $u(t) \\sim \\Pr(u(t))$ are modeled as i.i.d. noises added to the dynamics, and $\\Pr(x(1))$ is the distribution of initial states. We will approximate this problem using samples from $\\Pr(w(t))$, $\\Pr(u(t))$, and $\\Pr(x(1))$. To do so, we sample $\\{w(1)^{(i)},w(2)^{(i)},...,w(T)^{(i)}\\}_{i}^N$ from $\\Pr(w(t))$,  $\\{u(1)^{(i)},u(2)^{(i)},...,u(T)^{(i)}\\}_{i}^N$ from $\\Pr(u(t))$, and $\\{x(0)^{(i)}\\}_{i}^N$ from $\\Pr(x(1))$, where $N$ is the number of samples to be considered. Then we have the following problem instead:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\theta} \\quad & \\frac{1}{N}\\sum_{i=1}^N ||x^{(i)}(T)||^2 \\\\\n",
    "\\quad & d(t+1)^{(i)} = d(t)^{(i)} + v(t)^{(i)} + w(t)^{(i)} \\Delta t, \\\\\n",
    "\\quad & v(t+1)^{(i)} = v(t)^{(i)} + a(t)^{(i)} + u(t)^{(i)} \\Delta t, \\\\\n",
    "\\quad & a(t)^{(i)} = f_{\\theta}(x(t)^{(i)}), ~\\forall t=1,...,T-1, ~i=1,...,N \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The code up this new problem, you will fully utilize the tensor operations in PyTorch. For example, the state tensor \"x\" will now become a N-by-2 matrix, where the first dimension represents the number of trajectories to be optimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-wealth",
   "metadata": {},
   "source": [
    "## 4. Grading\n",
    "\n",
    "* (30%) Documentation of the problem formulation: Clearly describe the objective function, the variables, the constraints, and the assumptions involved in formulating the problem.\n",
    "\n",
    "* (40%) Programming: Like for homeworks, please push you code to your github repo. Please comment your code so that it is useful to you in the future.\n",
    "\n",
    "* (30%) Analysis of the results: Please document the convergence and the optimal solutions (e.g., the state trajectory if it is a control problem).\n",
    "\n",
    "* (Bonus 20%) Formulation of a problem different from rocket landing: The PyTorch framework can also be used for other engineering problems, e.g., for structure design with nonlinear mechanical properties. You get 20 bonus points for solving your own problems that are at least at the same level of difficulty as rocket landing. \n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d941a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}